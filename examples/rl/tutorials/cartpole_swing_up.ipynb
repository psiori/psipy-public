{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole Swingup\n",
    "This tutorial will explain how to train a controller to perform the batch and growing batch learning tasks.\n",
    "\n",
    "We will be using CartPole-v0, from the OpenAI gym, for the Batch tutorial, and CartPoleSway, a Psiori gym environment, for the Growing Batch tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "from psipy.rl.loop import Loop\n",
    "from psipy.rl.control.controller import DiscreteRandomActionController\n",
    "from psipy.rl.io.batch import Batch, Episode\n",
    "\n",
    "LOG = logging.getLogger(\"psipy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "There are two learning paradigms: batch and growing batch.\n",
    "### Batch\n",
    "In the batch paradigm, data is collected through some means, either a random controller, human, or otherwise.  A controller is fit on this data until convergence, and applied to the plant to test final performance.  In simple tasks, this should be sufficient.\n",
    "<img src=\"batch-paradigm.png\">\n",
    "### Growing Batch\n",
    "In the growing batch paradigm, initial data can either be collected the same way as in the batch approach above, or specifically through an exploration policy of the controller.  The controller is then fitted, and it is used to collect *more* data from the plant.  The 'batch of data' grows, and the controller is trained on this bigger batch.  In this way, the controller essentially explores the state space itself, and can 'learn from its mistakes'.\n",
    "<img src=\"growing-paradigm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Tutorial\n",
    "It is best practice to lay out all your learning components for ease of use and reading.  Here, we define some placeholder variables for our plant, action, state, and lookback (how many observations are in a stack to create a state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyglet.canvas' has no attribute 'xlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/psipy/psipy/rl/plant/gym/envs/renderer.py:20\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rendering\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glClearColor\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'rendering' from 'gymnasium.envs.classic_control' (/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/gymnasium/envs/classic_control/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/pyglet/__init__.py:305\u001b[0m, in \u001b[0;36m_ModuleProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'xlib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpsipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcartpole_plants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     CartPoleGymAction,\n\u001b[1;32m      3\u001b[0m     CartPoleState,\n\u001b[1;32m      4\u001b[0m     CartPoleUnboundedPlant,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m plant \u001b[38;5;241m=\u001b[39m \u001b[43mCartPoleUnboundedPlant\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_renderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Note that it is instantiated!\u001b[39;00m\n\u001b[1;32m      8\u001b[0m action \u001b[38;5;241m=\u001b[39m CartPoleGymAction\n\u001b[1;32m      9\u001b[0m state \u001b[38;5;241m=\u001b[39m CartPoleState\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/psipy/psipy/rl/plant/gym/cartpole_plants.py:182\u001b[0m, in \u001b[0;36mCartPoleUnboundedPlant.__init__\u001b[0;34m(self, swingup, sway, cost_func, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswingup\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m swingup\n\u001b[1;32m    181\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msway\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sway\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCartPoleUnbounded-v0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswingup \u001b[38;5;241m=\u001b[39m swingup\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msway \u001b[38;5;241m=\u001b[39m sway\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/psipy/psipy/rl/plant/gym/gym_plant.py:51\u001b[0m, in \u001b[0;36mGymPlant.__init__\u001b[0;34m(self, env_name, cost_func, add_action_to_state, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m env_name \u001b[38;5;129;01min\u001b[39;00m AVAILABLE_ENVIRONMENTS, env_name\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcost_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# OpenAI original gyms do not accept kwargs\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORIGINAL GYM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/gymnasium/envs/registration.py:756\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload_env_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[1;32m    759\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/gymnasium/envs/registration.py:545\u001b[0m, in \u001b[0;36mload_env_creator\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 545\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.8/3.8.19/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/psipy/psipy/rl/plant/gym/envs/cartpole.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger, spaces\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcartpole\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CartPoleEnv\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpsipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplant\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrenderer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RenderMixin, RenderMixinTimeOnly\n\u001b[1;32m     28\u001b[0m FLOATMAX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     29\u001b[0m PRECISION \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/psipy/psipy/rl/plant/gym/envs/renderer.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glClearColor\n\u001b[1;32m     23\u001b[0m     Viewer \u001b[38;5;241m=\u001b[39m rendering\u001b[38;5;241m.\u001b[39mViewer\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNameError\u001b[39;00m, \u001b[43mpyglet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlib\u001b[49m\u001b[38;5;241m.\u001b[39mNoSuchDisplayException):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomViewer\u001b[39;00m(Viewer):\n",
      "File \u001b[0;32m~/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/pyglet/__init__.py:315\u001b[0m, in \u001b[0;36m_ModuleProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_module\u001b[39m\u001b[38;5;124m'\u001b[39m, module)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyglet.canvas' has no attribute 'xlib'"
     ]
    }
   ],
   "source": [
    "from psipy.rl.plant.gym.cartpole_plants import (\n",
    "    CartPoleGymAction,\n",
    "    CartPoleState,\n",
    "    CartPoleUnboundedPlant,\n",
    ")\n",
    "\n",
    "plant = CartPoleUnboundedPlant(use_renderer=True)  # Note that it is instantiated!\n",
    "action = CartPoleGymAction\n",
    "state = CartPoleState\n",
    "lookback = 2\n",
    "sart_folder = \"cartpole-swingup-sart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use NFQ to control this plant.  Therefore, we need a neural network internal model.  Below we use a function to create the model, but this is not necessary.  Note that we need to use the lookback here to make sure our network's inputs are properly shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.control.nfq import NFQ\n",
    "\n",
    "def make_model(n_inputs, n_outputs, lookback):\n",
    "    inp = tfkl.Input((n_inputs, lookback), name=\"state\")\n",
    "    net = tfkl.Flatten()(inp)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(n_outputs, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model(inp, net)\n",
    "\n",
    "model = make_model(n_inputs=len(state.channels()), \n",
    "                   # CartPolev0 only has 1 action with 2 values (see CartPoleAction)\n",
    "                   n_outputs=len(action.legal_values[0]), \n",
    "                   lookback=lookback)\n",
    "\n",
    "# Create the controller with our model.  \n",
    "controller = NFQ(model=model, state_channels=state.channels(), action=action, action_values=(0,1), lookback=lookback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want a controller to explore.  We could use NFQ to explore, since with randomized weights it essentially acts as a random controller, but we will explicitly use a random controller here to demonstrate how to use different controllers at the same time. Since `CartPoleAction` is discrete, we use a `DiscreteRandomActionController`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explorer = DiscreteRandomActionController(state_channels=state.channels(), action=action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `Loop`, which takes a name (the name in the SART logs), a plant, a controller, and a path to save the SART logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, explorer, \"GymCartPole\", sart_folder, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now collect some data with our explorer, the `DiscreteRandomActionController`.  We want to collect 50 episodes, and since the OpenAI gyms control for `max_episode_steps` already, we don't have to specify that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v0\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "env.action_space.contains(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loop.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "a = action({'move': 1})\n",
    "pprint (a.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that if you run this notebook multiple times, old data collected from previous runs will also be loaded unless you have deleted the SART folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data into a `Batch` from the hdf5 files we just created.  Be aware that you have to set the lookback here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "files = os.listdir(\"tutorial-batch-sart/\")\n",
    "\n",
    "filename = files[0]\n",
    "print(f\"file {filename}\")\n",
    "f = h5py.File(os.path.join(\"tutorial-batch-sart/\", filename), 'r')\n",
    "print(f.keys())\n",
    "print(f['action'].keys())\n",
    "print(f['action']['move'])\n",
    "print(f['action']['move'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_hdf5(sart_folder, lookback=lookback, control=controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note the logs: at the bottom, the logs will always tell you how many episodes were loaded.  If you want to know at any other point how many episodes the batch has loaded, check the `num_episodes` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.num_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks like normalized data, so we fit NFQ's normalizer on the observations in the batch.  We have to pass in the batch's observations to fit the normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.fit_normalizer(batch.observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for fitting.  We pass in the batch, and train.  This will take a couple minutes (not too long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(batch.states_actions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.fit(\n",
    "    batch,\n",
    "    iterations=5,\n",
    "    epochs=20,\n",
    "    minibatch_size=32,\n",
    "    gamma=1.0,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray!  Now we can see how our trained controller fairs live in the plant.  Let's run the controller again by creating a new `Loop`, but this time not store the data in our SART folder (otherwise if we want to train again we will train on this data as well, i.e. growing batch).  We do this by changing the `logdir` param to something different from our SART folder.  I prefer prepending \"live-\" to the SART folder name.  Finally, we render the environment so we can see what is happening.  Enjoy!\n",
    "\n",
    "*Note: the environment will not close on its own. We know of this issue and won't fix it (yet) :D*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loop = Loop(plant, controller, \"CartPoleEval\", f\"live-{sart_folder}\", render=True)\n",
    "eval_loop.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 10\n",
    "iterations = 5\n",
    "\n",
    "loop = Loop(plant, controller, \"GymCartPole\", sart_folder, render=True)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "    loop.run(5)\n",
    "\n",
    "    batch.append_from_hdf5(sart_folder)\n",
    "    print(f\"Current batch size: {batch.num_episodes}\")\n",
    "\n",
    "    controller.fit(\n",
    "        batch,\n",
    "        iterations=50,\n",
    "        epochs=30,\n",
    "        minibatch_size=32,\n",
    "        gamma=1.0,\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing Batch Tutorial\n",
    "We will use the `CartPoleSway` env here, since `CartPole-v0` has a hardcoded discrete action space.\n",
    "\n",
    "As with the Batch tutorial, we will lay out all of our learning components for ease of use and reading.  Here, we define some placeholder variables for our plant, action, state, and lookback (how many observations are in a stack to create a state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.plant.gym.cartpole_plants import (\n",
    "    CartPoleSwayContAction,\n",
    "    CartPoleSwayContinuousPlant,\n",
    "    CartPoleSwayState,\n",
    ")\n",
    "\n",
    "plant = CartPoleSwayContinuousPlant()  # Note that it is instantiated!\n",
    "action = CartPoleSwayContAction\n",
    "state = CartPoleSwayState\n",
    "lookback = 1\n",
    "sart_folder = \"tutorial-growing-sart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use NFQCA to control this plant.  Therefore, we need a two neural network internal models, one for the actor and one for the critic.  Below we use functions to create the models, but this is not necessary.  Note that we need to use the lookback to properly shape our neural networks' inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.control.nfqca import NFQCA\n",
    "\n",
    "def make_actor(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_actor\")\n",
    "    net = tfkl.Flatten()(inp)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"tanh\")(net)\n",
    "    return tf.keras.Model(inp, net, name=\"actor\")\n",
    "\n",
    "\n",
    "def make_critic(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_critic\")\n",
    "    act = tfkl.Input((1,), name=\"act_in\")\n",
    "    net = tfkl.Concatenate()([tfkl.Flatten()(inp), tfkl.Flatten()(act)])\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model([inp, act], net, name=\"critic\")\n",
    "\n",
    "actor = make_actor(len(state.channels()), lookback)\n",
    "critic = make_critic(len(state.channels()), lookback)\n",
    "\n",
    "controller = NFQCA(\n",
    "    actor=actor, \n",
    "    critic=critic, \n",
    "    state_channels=state.channels(), \n",
    "    action=CartPoleSwayContAction,\n",
    "    lookback=lookback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `Loop`, which takes a name (the name in the SART logs), a plant, a controller, and a path to save the SART logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, controller, \"CartPoleSway\", sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use NFQCA to do the initial exploration, as well as all data collection.  We first collect some initial data outside the loop and then collect more data within the growing-batch-loop.  We print some extra things so you can see what is going on, but that is unnecessary.\n",
    "\n",
    "Note that depending on the internal cost function of the `CartPoleSwayEnv` at this time, NFQCA might learn nothing.  This tutorial just shows the general form of training NFQCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 3\n",
    "iterations = 2\n",
    "\n",
    "loop.run(10)\n",
    "batch = Batch.from_hdf5(sart_folder, lookback=lookback, control=controller)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "    LOG.info(\"Cycle: %d\", cycle + 1)\n",
    "    print(f\"Current batch size: {batch.num_episodes}\")\n",
    "    # Fit the normalizer on the data. Fitting iteratively makes the fit \n",
    "    # parameters hone in on the true population parameters \n",
    "    # (See Batch Tutorial above for more detail on how normalization works)\n",
    "    controller.fit_normalizer(batch.observations, method=\"meanstd\")\n",
    "\n",
    "    # NFQCA does not have a generic fit method\n",
    "    for iteration in range(iterations):\n",
    "        LOG.info(\"NFQCA Iteration: %d\", iteration + 1)\n",
    "        controller.fit_critic(batch,\n",
    "                         iterations=1,\n",
    "                         epochs=10,\n",
    "                         minibatch_size=-1,\n",
    "                         gamma=1.0,\n",
    "                         verbose=0)\n",
    "        controller.fit_actor(batch,\n",
    "                        epochs=10,\n",
    "                        minibatch_size=-1,\n",
    "                        verbose=0)\n",
    "\n",
    "    loop = Loop(plant, controller, \"GrowingBatch\", sart_folder)\n",
    "    loop.run(5)\n",
    "    # Batch.append_from_hdf5() appends any new files found in the folder\n",
    "    batch.append_from_hdf5(sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how the model performs live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, controller, \"GrowingBatchEval\", f\"live-{sart_folder}\", render=True)\n",
    "loop.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've made it to the next level! Congratulations.  Now it is time to delve deeper into the power of offline reinforcement learning.  The general guidelines training will not be outlined here.\n",
    "\n",
    "Let's train `CartPoleSway` again, but this time alter the cost function and create fake transitions to aid the cart to its goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Setting\n",
    "We want the cart to move the position 0 (middle of the screen) from any starting position.  We do not care about the pole.\n",
    "\n",
    "For this, we will generate a cost function that only deals out cost based on position, and create a fake transition set that shows 0 cost at the goal position.\n",
    "\n",
    "*Note the imports inside the functions: this is bad practice but I do it here to show what imports we need.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_episodes(sart_path:str, lookback:int): # ->List[Episode]\n",
    "    \"\"\"Create a fake episode at position 0 for every episode already collected\n",
    "    \n",
    "    Since the cart probably was never at position 0 exactly, we add a set of Episodes with this transition.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    from psipy.rl.io.sart import SARTReader\n",
    "    from psipy.rl.io.batch import Episode\n",
    "    \n",
    "    more_episodes = []\n",
    "\n",
    "    for path in glob.glob(f\"{sart_path}/*.hdf5\"):\n",
    "        with SARTReader(path) as reader:\n",
    "            o, a, t, c = reader.load_full_episode()\n",
    "\n",
    "            # Add episode full of goal states\n",
    "            o = o.copy()\n",
    "            a = a.copy()\n",
    "            o[:, 0] = 0\n",
    "            o[:, 1] = 0\n",
    "            # A swinging pole affects the position of the cart,\n",
    "            # so we say no swing here as well\n",
    "            o[:, 2] = 180\n",
    "            o[:, 3] = 0\n",
    "            a[:] = 0  # The cart should not move once in this position\n",
    "            more_episodes.append(Episode(o, a, t, c, lookback=lookback))\n",
    "            \n",
    "    return more_episodes\n",
    "\n",
    "def costfunc(states:np.ndarray): # -> np.ndarray\n",
    "    \"\"\"Recalculate costs on all states provided\n",
    "    \n",
    "    This calculates costs on multiple states, so it returns an array\n",
    "    \"\"\"\n",
    "    from psipy.rl.control.nfq import tanh2\n",
    "    # Position is already defined against 0 (relative)\n",
    "    position = states[:, 0]\n",
    "    cost = tanh2(position, C=.2, mu=.1)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set everything up until we need to add the fake transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.plant.gym.cartpole_plants import (\n",
    "    CartPoleSwayContAction,\n",
    "    CartPoleSwayContinuousPlant,\n",
    "    CartPoleSwayState,\n",
    ")\n",
    "from psipy.rl.control.nfqca import NFQCA\n",
    "\n",
    "\n",
    "plant = CartPoleSwayContinuousPlant()  # Note that it is instantiated!\n",
    "action = CartPoleSwayContAction\n",
    "state = CartPoleSwayState\n",
    "lookback = 5\n",
    "sart_folder = \"tutorial-advanced-sart\"\n",
    "\n",
    "\n",
    "def make_actor(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_actor\")\n",
    "    net = tfkl.Flatten()(inp)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"tanh\")(net)\n",
    "    return tf.keras.Model(inp, net, name=\"actor\")\n",
    "\n",
    "\n",
    "def make_critic(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_critic\")\n",
    "    act = tfkl.Input((1,), name=\"act_in\")\n",
    "    net = tfkl.Concatenate()([tfkl.Flatten()(inp), tfkl.Flatten()(act)])\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model([inp, act], net, name=\"critic\")\n",
    "\n",
    "actor = make_actor(len(state.channels()), lookback)\n",
    "critic = make_critic(len(state.channels()), lookback)\n",
    "\n",
    "controller = NFQCA(\n",
    "    actor=actor, \n",
    "    critic=critic, \n",
    "    state_channels=state.channels(), \n",
    "    action=CartPoleSwayContAction,\n",
    "    lookback=lookback\n",
    ")\n",
    "\n",
    "loop = Loop(plant, controller, \"CartPolePosition\", sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critic recieves the cost function, and before we start training we want to add our fake goal position transitions.  Therefore, we put `costfunc` in `fit_critic` and append fake episodes before we start the fitting cycles.\n",
    "\n",
    "We will print the size of the batch so it can be seen how the fake episodes increase the batch episode count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 3\n",
    "iterations = 3\n",
    "\n",
    "loop.run(10)\n",
    "batch = Batch.from_hdf5(sart_folder, lookback=lookback, control=controller)\n",
    "print(f\"Current batch size: {batch.num_episodes}\")\n",
    "# We now append the fake created episodes\n",
    "# We could also throw away the created batch and only have the episodes\n",
    "# created in the function by doing:\n",
    "# batch = Batch(create_fake_episodes(sart_folder, lookback))\n",
    "batch = batch.append(create_fake_episodes(sart_folder, lookback))\n",
    "        \n",
    "for cycle in range(num_cycles):\n",
    "    LOG.info(\"Cycle: %d\", cycle + 1)\n",
    "    print(f\"Current batch size: {batch.num_episodes}\")\n",
    "    controller.fit_normalizer(batch.observations, method=\"meanstd\")\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        LOG.info(\"NFQCA Iteration: %d\", iteration + 1)\n",
    "        controller.fit_critic(batch,\n",
    "                         iterations=1,\n",
    "                         # We add the cost function here\n",
    "                         costfunc=costfunc,\n",
    "                         epochs=10,\n",
    "                         minibatch_size=-1,\n",
    "                         gamma=1.0,\n",
    "                         verbose=0)\n",
    "        controller.fit_actor(batch,\n",
    "                        epochs=10,\n",
    "                        minibatch_size=-1,\n",
    "                        verbose=0)\n",
    "\n",
    "    loop = Loop(plant, controller, \"GrowingBatch\", sart_folder)\n",
    "    loop.run(10)\n",
    "    batch.append_from_hdf5(sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the controller moves to the goal position.  Oh the tension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, controller, \"GrowingBatchEval\", f\"live-{sart_folder}\", render=True)\n",
    "loop.run(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you've made it through the Advanced Tutorial.  You are now an expert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please delete the SART logs created by this tutorial if you no longer need them.  Or run the cell below to do that automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "dirs = [\"tutorial-advanced-sart\", \n",
    "        \"tutorial-batch-sart\", \n",
    "        \"tutorial-growing-batch\", \n",
    "        \"live-tutorial-growing-sart\", \n",
    "        \"live-tutorial-batch-sart\", \n",
    "        \"live-tutorial-advanced-sart\"]\n",
    "for d in dirs:\n",
    "    try:\n",
    "        shutil.rmtree(d)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
