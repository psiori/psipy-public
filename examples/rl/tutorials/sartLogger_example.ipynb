{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os, time\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, Tuple, List, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from psipy.rl.plant import Action, State, Plant\n",
    "from psipy.rl.control.controller import Controller\n",
    "from psipy.rl.control.controller import DiscreteRandomActionController\n",
    "from psipy.rl.io.sart import SARTLogger\n",
    "from psipy.rl.cycle_manager import CM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage:\n",
    "This notebook is a combination of \"cycle_manager_toturial.ipython\" and \"episode_io_toturial.ipython\". In order to make it happen, we will put time.sleep() in our loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestState(State):\n",
    "    _channels = (\"sensor1\", \"sensor2\")\n",
    "\n",
    "class TestAction(Action):\n",
    "    dtype = \"discrete\"\n",
    "    num_values = 1\n",
    "    channels = (\"act1\", \"act1/2\")  # / will transform to | (pipe) since it conflicts with hdf5 group paths!\n",
    "    legal_values = (range(101), range(101))\n",
    "\n",
    "class TestPlant(Plant):\n",
    "    state_type = TestState\n",
    "    action_type = TestAction\n",
    "\n",
    "    def check_initial_state(self, state: State) -> State:\n",
    "        return self._get_next_state(TestState({\"sensor1\": 10, \"sensor2\":20}), None)\n",
    "\n",
    "    def _get_next_state(self, state: State, action: Action) -> State:\n",
    "        state.terminal = False\n",
    "        state.reward = 1\n",
    "        return TestState({\"sensor1\": 10, \"sensor2\": 20})\n",
    "\n",
    "    def notify_episode_stops(self) -> bool:\n",
    "        pass\n",
    "\n",
    "plant = TestPlant()\n",
    "name = \"TutorialRun\"\n",
    "logdir = os.path.join(\".\", \"test-logs\")\n",
    "max_steps = 100  # just how many loops we will do in the \"episode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "PATH:\n",
      "'state/values/sensor1'\n",
      "PATH:\n",
      "'state/values/sensor2'\n",
      "PATH:\n",
      "'state/cost'\n",
      "PATH:\n",
      "'state/terminal'\n",
      "PATH:\n",
      "'action/act1'\n",
      "PATH:\n",
      "'action/act1|2'\n",
      "PATH:\n",
      "'action/act1_index'\n",
      "PATH:\n",
      "'action/act1|2_index'\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x16837e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 118, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 153, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 127, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/psipy/psipy/rl/io/sart.py\", line 124, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/dm-psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "tock\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n",
      "RESIZE!\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "plant.notify_episode_starts()\n",
    "state = plant.check_initial_state(None)\n",
    "\n",
    "drc = DiscreteRandomActionController(TestState.channels(), TestAction)\n",
    "\n",
    "CM.notify_episode_starts(\n",
    "    1,\n",
    "    plant.__class__.__name__,\n",
    "    \"control\",\n",
    ")\n",
    "sart = SARTLogger(logdir, name)\n",
    "sart.notify_episode_starts()\n",
    "new_file = True\n",
    "for _ in range(33 * 10):  # 3s\n",
    "    CM[\"loop\"].tick()\n",
    "    with CM[\"get-action\"]:\n",
    "        action = drc.get_action(state)\n",
    "    with CM[\"get-state\"]:\n",
    "        next_state = plant.get_next_state(state, action)\n",
    "        reward = plant.get_cost(next_state)\n",
    "        terminal = plant.is_terminal(next_state)\n",
    "    action_dict = action.as_dict(with_additional=True)\n",
    "    data = dict(state=state.as_dict(), action=action_dict)\n",
    "    CM.step(data)  # Increments step counter.\n",
    "\n",
    "    with CM[\"sart-append\"]:\n",
    "        sart.append(data)\n",
    "    state = next_state\n",
    "\n",
    "    if terminal:\n",
    "        data = dict(\n",
    "            state=next_state.as_dict(),\n",
    "            action=OrderedDict({k: np.nan for k in action.channels}),\n",
    "        )\n",
    "        sart.append(data)\n",
    "        CM.step(data, increment_step_counter=False)\n",
    "        break\n",
    "    # User initiated episode stop / loop exit or max_steps reached.\n",
    "    if CM.should_stop(max_steps=max_steps):\n",
    "        break_all = CM.notify_episode_stops()\n",
    "        break\n",
    "        \n",
    "    time.sleep(1/30)  # 30hz\n",
    "    print(\"tock\")\n",
    "    CM[\"loop\"].tock()\n",
    "\n",
    "plant.notify_episode_stops()\n",
    "sart.notify_episode_stops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file TutorialRun-240903-123836-0-00.h5\n",
      "<KeysViewHDF5 ['action', 'state']>\n",
      "<KeysViewHDF5 ['cost', 'terminal', 'values']>\n",
      "<KeysViewHDF5 ['sensor1', 'sensor2']>\n",
      "(100,)\n",
      "file TutorialRun-240903-124347-0-00.h5\n",
      "<KeysViewHDF5 ['action', 'state']>\n",
      "<KeysViewHDF5 ['cost', 'terminal', 'values']>\n",
      "<KeysViewHDF5 ['sensor1', 'sensor2']>\n",
      "(100,)\n",
      "file TutorialRun-240903-123637-0-00.h5\n",
      "<KeysViewHDF5 ['action', 'state']>\n",
      "<KeysViewHDF5 ['cost', 'terminal', 'values']>\n",
      "<KeysViewHDF5 ['sensor1', 'sensor2']>\n",
      "(1,)\n",
      "file TutorialRun-240903-123805-0-00.h5\n",
      "<KeysViewHDF5 ['action', 'state']>\n",
      "<KeysViewHDF5 ['cost', 'terminal', 'values']>\n",
      "<KeysViewHDF5 ['sensor1', 'sensor2']>\n",
      "(100,)\n",
      "file TutorialRun-240903-123906-0-00.h5\n",
      "<KeysViewHDF5 ['action', 'state']>\n",
      "<KeysViewHDF5 ['cost', 'terminal', 'values']>\n",
      "<KeysViewHDF5 ['sensor1', 'sensor2']>\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "files = os.listdir(\"test-logs/\")\n",
    "for filename in files:\n",
    "    try:\n",
    "        f = h5py.File(os.path.join(\"test-logs/\", filename), 'r')\n",
    "        print(f\"file {filename}\")\n",
    "        print(f.keys())\n",
    "        print(f['state'].keys())\n",
    "        print(f['state']['values'].keys())\n",
    "        print(f['state']['values']['sensor2'][:].shape)\n",
    "    except:\n",
    "        print(f\"file {filename} is corrupted\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['sensor1', 'sensor2']>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f['state']['values'].keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
