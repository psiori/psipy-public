{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Learning Tutorials\n",
    "This tutorial will explain how to train a controller to perform the batch and growing batch learning tasks.\n",
    "\n",
    "We will be using CartPole-v0, from the OpenAI gym, for the Batch tutorial, and CartPoleSway, a Psiori gym environment, for the Growing Batch tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "from psipy.rl.loop import Loop\n",
    "from psipy.rl.core.controller import DiscreteRandomActionController, ContinuousRandomActionController\n",
    "from psipy.rl.io.batch import Batch, Episode\n",
    "\n",
    "LOG = logging.getLogger(\"psipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v0\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in range(1000):\n",
    "   action = env.action_space.sample()  # this is where you would insert your policy\n",
    "   observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "   if terminated or truncated:\n",
    "      observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "There are two learning paradigms: batch and growing batch.\n",
    "### Batch\n",
    "In the batch paradigm, data is collected through some means, either a random controller, human, or otherwise.  A controller is fit on this data until convergence, and applied to the plant to test final performance.  In simple tasks, this should be sufficient.\n",
    "<img src=\"batch-paradigm.png\">\n",
    "### Growing Batch\n",
    "In the growing batch paradigm, initial data can either be collected the same way as in the batch approach above, or specifically through an exploration policy of the controller.  The controller is then fitted, and it is used to collect *more* data from the plant.  The 'batch of data' grows, and the controller is trained on this bigger batch.  In this way, the controller essentially explores the state space itself, and can 'learn from its mistakes'.\n",
    "<img src=\"growing-paradigm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Tutorial\n",
    "It is best practice to lay out all your learning components for ease of use and reading.  Here, we define some placeholder variables for our plant, action, state, and lookback (how many observations are in a stack to create a state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL GYM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v1 is out of date. You should consider upgrading to version `v2`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "from psipy.rl.plants.gym.cartpole_plants import (\n",
    "    CartPoleGymAction,\n",
    "    CartPoleState,\n",
    "    CartPolePlant,\n",
    ")\n",
    "\n",
    "plant = CartPolePlant(use_renderer=True)  # Note that it is instantiated!\n",
    "action = CartPoleGymAction\n",
    "state = CartPoleState\n",
    "lookback = 2\n",
    "sart_folder = \"data_tutorial-batch-sart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use NFQ to control this plant.  Therefore, we need a neural network internal model.  Below we use a function to create the model, but this is not necessary.  Note that we need to use the lookback here to make sure our network's inputs are properly shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizer not fitted, returning values unchanged.\n"
     ]
    }
   ],
   "source": [
    "from psipy.rl.controllers.nfq import NFQ\n",
    "\n",
    "def make_model(n_inputs, n_outputs, lookback):\n",
    "    inp = tfkl.Input((n_inputs, lookback), name=\"state\")\n",
    "    net = tfkl.Flatten()(inp)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(n_outputs, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model(inp, net)\n",
    "\n",
    "model = make_model(n_inputs=len(state.channels()), \n",
    "                   # CartPolev0 only has 1 action with 2 values (see CartPoleAction)\n",
    "                   n_outputs=len(action.legal_values[0]), \n",
    "                   lookback=lookback)\n",
    "\n",
    "# Create the controller with our model.  \n",
    "controller = NFQ(model=model, state_channels=state.channels(), action=action, action_values=(0,1), lookback=lookback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want a controller to explore.  We could use NFQ to explore, since with randomized weights it essentially acts as a random controller, but we will explicitly use a random controller here to demonstrate how to use different controllers at the same time. Since `CartPoleAction` is discrete, we use a `DiscreteRandomActionController`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "explorer = DiscreteRandomActionController(state_channels=state.channels(), action=action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `Loop`, which takes a name (the name in the SART logs), a plant, a controller, and a path to save the SART logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, explorer, \"GymCartPole\", sart_folder, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now collect some data with our explorer, the `DiscreteRandomActionController`.  We want to collect 50 episodes, and since the OpenAI gyms control for `max_episode_steps` already, we don't have to specify that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v0\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "env.action_space.contains(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:25:29.079 Python[41958:1341697] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/3d/_pkw6ngs6bd4cdys6p7g7wf40000gn/T/org.python.python.savedState\n",
      "2024-09-05 19:25:29.482 Python[41958:1341697] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-09-05 19:25:29.482 Python[41958:1341697] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n",
      "ACTION:\n",
      "{'move': 1}\n",
      "ACTION:\n",
      "{'move': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'total_cost': 0.49441114241218703,\n",
       "  'cycles_run': 56,\n",
       "  'wall_time_s': 2.5816},\n",
       " 2: {'total_cost': 0.07699957024230178,\n",
       "  'cycles_run': 11,\n",
       "  'wall_time_s': 0.7506},\n",
       " 3: {'total_cost': 0.3214663204183065,\n",
       "  'cycles_run': 37,\n",
       "  'wall_time_s': 1.3009},\n",
       " 4: {'total_cost': 0.09004889708471091,\n",
       "  'cycles_run': 12,\n",
       "  'wall_time_s': 0.7676},\n",
       " 5: {'total_cost': 0.1218215968684984,\n",
       "  'cycles_run': 18,\n",
       "  'wall_time_s': 0.8929}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "a = action({'move': 1})\n",
    "pprint (a.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that if you run this notebook multiple times, old data collected from previous runs will also be loaded unless you have deleted the SART folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data into a `Batch` from the hdf5 files we just created.  Be aware that you have to set the lookback here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "files = os.listdir(\"tutorial-batch-sart/\")\n",
    "\n",
    "filename = files[0]\n",
    "print(f\"file {filename}\")\n",
    "f = h5py.File(os.path.join(\"tutorial-batch-sart/\", filename), 'r')\n",
    "print(f.keys())\n",
    "print(f['action'].keys())\n",
    "print(f['action']['move'])\n",
    "print(f['action']['move'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_hdf5(sart_folder, lookback=lookback, control=controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note the logs: at the bottom, the logs will always tell you how many episodes were loaded.  If you want to know at any other point how many episodes the batch has loaded, check the `num_episodes` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.num_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks like normalized data, so we fit NFQ's normalizer on the observations in the batch.  We have to pass in the batch's observations to fit the normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.fit_normalizer(batch.observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for fitting.  We pass in the batch, and train.  This will take a couple minutes (not too long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(batch.states_actions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 0s 817us/step - loss: 0.0263 - min_q: 0.2040 - avg_q: 0.3726 - max_q: 0.6262\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 0s 698us/step - loss: 0.0052 - min_q: 0.1206 - avg_q: 0.2606 - max_q: 0.5621\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 0s 744us/step - loss: 0.0048 - min_q: 0.1189 - avg_q: 0.2588 - max_q: 0.5510\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 0s 676us/step - loss: 0.0046 - min_q: 0.1198 - avg_q: 0.2600 - max_q: 0.5382\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 0s 685us/step - loss: 0.0044 - min_q: 0.1182 - avg_q: 0.2594 - max_q: 0.5441\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 0s 677us/step - loss: 0.0044 - min_q: 0.1180 - avg_q: 0.2594 - max_q: 0.5408\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 0s 722us/step - loss: 0.0043 - min_q: 0.1180 - avg_q: 0.2596 - max_q: 0.5443\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 0s 801us/step - loss: 0.0042 - min_q: 0.1156 - avg_q: 0.2595 - max_q: 0.5429\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 0s 801us/step - loss: 0.0041 - min_q: 0.1160 - avg_q: 0.2597 - max_q: 0.5443\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 0s 801us/step - loss: 0.0042 - min_q: 0.1143 - avg_q: 0.2590 - max_q: 0.5410\n",
      "Epoch 1/10\n",
      "87/87 [==============================] - 0s 797us/step - loss: 0.0065 - min_q: 0.0971 - avg_q: 0.2034 - max_q: 0.4927\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 0s 782us/step - loss: 0.0057 - min_q: 0.0899 - avg_q: 0.1953 - max_q: 0.5095\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 0s 771us/step - loss: 0.0055 - min_q: 0.0891 - avg_q: 0.1956 - max_q: 0.5140\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 0s 774us/step - loss: 0.0053 - min_q: 0.0882 - avg_q: 0.1957 - max_q: 0.5197\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 0s 754us/step - loss: 0.0052 - min_q: 0.0871 - avg_q: 0.1957 - max_q: 0.5179\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 0s 770us/step - loss: 0.0050 - min_q: 0.0854 - avg_q: 0.1962 - max_q: 0.5191\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 0s 776us/step - loss: 0.0050 - min_q: 0.0834 - avg_q: 0.1961 - max_q: 0.5270\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 0s 772us/step - loss: 0.0049 - min_q: 0.0839 - avg_q: 0.1961 - max_q: 0.5235\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 0s 725us/step - loss: 0.0048 - min_q: 0.0826 - avg_q: 0.1958 - max_q: 0.5265\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 0s 756us/step - loss: 0.0047 - min_q: 0.0817 - avg_q: 0.1962 - max_q: 0.5291\n"
     ]
    }
   ],
   "source": [
    "controller.fit(\n",
    "    batch,\n",
    "    iterations=2,\n",
    "    epochs=10,\n",
    "    minibatch_size=32,\n",
    "    gamma=1.0,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray!  Now we can see how our trained controller fairs live in the plant.  Let's run the controller again by creating a new `Loop`, but this time not store the data in our SART folder (otherwise if we want to train again we will train on this data as well, i.e. growing batch).  We do this by changing the `logdir` param to something different from our SART folder.  I prefer prepending \"live-\" to the SART folder name.  Finally, we render the environment so we can see what is happening.  Enjoy!\n",
    "\n",
    "*Note: the environment will not close on its own. We know of this issue and won't fix it (yet) :D*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
      "Exception ignored in: <function ExpandableDataset.__del__ at 0x31dc5d160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 114, in __del__\n",
      "    self.finalize()\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 147, in finalize\n",
      "    self._resize(self.rows)\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 121, in _resize\n",
      "    raise e\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/psipy-public/psipy/rl/io/sart.py\", line 118, in _resize\n",
      "    self.dataset.resize((rows, *self.incoming_shape))\n",
      "  File \"/Users/slange/Code/sabbatical/psiori/.venv/lib/python3.8/site-packages/h5py/_hl/dataset.py\", line 659, in resize\n",
      "    self.id.set_extent(size)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 277, in h5py.h5d.DatasetID.set_extent\n",
      "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 0.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n",
      "ACTION:\n",
      "{'move': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'total_cost': 0.06462697562744499,\n",
       "  'cycles_run': 10,\n",
       "  'wall_time_s': 0.7577},\n",
       " 2: {'total_cost': 0.06512353236199483,\n",
       "  'cycles_run': 9,\n",
       "  'wall_time_s': 0.7058},\n",
       " 3: {'total_cost': 0.053515641239248395,\n",
       "  'cycles_run': 9,\n",
       "  'wall_time_s': 0.7053},\n",
       " 4: {'total_cost': 0.0606901352040561,\n",
       "  'cycles_run': 10,\n",
       "  'wall_time_s': 0.7244},\n",
       " 5: {'total_cost': 0.0661851217023423,\n",
       "  'cycles_run': 10,\n",
       "  'wall_time_s': 0.7301}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loop = Loop(plant, controller, \"CartPoleEval\", f\"{sart_folder}-evaluation\", render=True)\n",
    "eval_loop.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 10\n",
    "iterations = 5\n",
    "\n",
    "loop = Loop(plant, controller, \"GymCartPole\", sart_folder, render=True)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "    loop.run(5)\n",
    "\n",
    "    batch.append_from_hdf5(sart_folder)\n",
    "    print(f\"Current batch size: {batch.num_episodes}\")\n",
    "\n",
    "    controller.fit(\n",
    "        batch,\n",
    "        iterations=50,\n",
    "        epochs=30,\n",
    "        minibatch_size=32,\n",
    "        gamma=1.0,\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing Batch Tutorial\n",
    "We will use the `CartPoleSway` env here, since `CartPole-v0` has a hardcoded discrete action space.\n",
    "\n",
    "As with the Batch tutorial, we will lay out all of our learning components for ease of use and reading.  Here, we define some placeholder variables for our plant, action, state, and lookback (how many observations are in a stack to create a state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.plant.gym.cartpole_plants import (\n",
    "    CartPoleSwayContAction,\n",
    "    CartPoleSwayContinuousPlant,\n",
    "    CartPoleSwayState,\n",
    ")\n",
    "\n",
    "plant = CartPoleSwayContinuousPlant()  # Note that it is instantiated!\n",
    "action = CartPoleSwayContAction\n",
    "state = CartPoleSwayState\n",
    "lookback = 1\n",
    "sart_folder = \"tutorial-growing-sart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use NFQCA to control this plant.  Therefore, we need a two neural network internal models, one for the actor and one for the critic.  Below we use functions to create the models, but this is not necessary.  Note that we need to use the lookback to properly shape our neural networks' inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.control.nfqca import NFQCA\n",
    "\n",
    "def make_actor(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_actor\")\n",
    "    net = tfkl.Flatten()(inp)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"tanh\")(net)\n",
    "    return tf.keras.Model(inp, net, name=\"actor\")\n",
    "\n",
    "\n",
    "def make_critic(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_critic\")\n",
    "    act = tfkl.Input((1,), name=\"act_in\")\n",
    "    net = tfkl.Concatenate()([tfkl.Flatten()(inp), tfkl.Flatten()(act)])\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model([inp, act], net, name=\"critic\")\n",
    "\n",
    "actor = make_actor(len(state.channels()), lookback)\n",
    "critic = make_critic(len(state.channels()), lookback)\n",
    "\n",
    "controller = NFQCA(\n",
    "    actor=actor, \n",
    "    critic=critic, \n",
    "    state_channels=state.channels(), \n",
    "    action=CartPoleSwayContAction,\n",
    "    lookback=lookback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `Loop`, which takes a name (the name in the SART logs), a plant, a controller, and a path to save the SART logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, controller, \"CartPoleSway\", sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use NFQCA to do the initial exploration, as well as all data collection.  We first collect some initial data outside the loop and then collect more data within the growing-batch-loop.  We print some extra things so you can see what is going on, but that is unnecessary.\n",
    "\n",
    "Note that depending on the internal cost function of the `CartPoleSwayEnv` at this time, NFQCA might learn nothing.  This tutorial just shows the general form of training NFQCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 3\n",
    "iterations = 2\n",
    "\n",
    "loop.run(10)\n",
    "batch = Batch.from_hdf5(sart_folder, lookback=lookback, control=controller)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "    LOG.info(\"Cycle: %d\", cycle + 1)\n",
    "    print(f\"Current batch size: {batch.num_episodes}\")\n",
    "    # Fit the normalizer on the data. Fitting iteratively makes the fit \n",
    "    # parameters hone in on the true population parameters \n",
    "    # (See Batch Tutorial above for more detail on how normalization works)\n",
    "    controller.fit_normalizer(batch.observations, method=\"meanstd\")\n",
    "\n",
    "    # NFQCA does not have a generic fit method\n",
    "    for iteration in range(iterations):\n",
    "        LOG.info(\"NFQCA Iteration: %d\", iteration + 1)\n",
    "        controller.fit_critic(batch,\n",
    "                         iterations=1,\n",
    "                         epochs=10,\n",
    "                         minibatch_size=-1,\n",
    "                         gamma=1.0,\n",
    "                         verbose=0)\n",
    "        controller.fit_actor(batch,\n",
    "                        epochs=10,\n",
    "                        minibatch_size=-1,\n",
    "                        verbose=0)\n",
    "\n",
    "    loop = Loop(plant, controller, \"GrowingBatch\", sart_folder)\n",
    "    loop.run(5)\n",
    "    # Batch.append_from_hdf5() appends any new files found in the folder\n",
    "    batch.append_from_hdf5(sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how the model performs live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, controller, \"GrowingBatchEval\", f\"live-{sart_folder}\", render=True)\n",
    "loop.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've made it to the next level! Congratulations.  Now it is time to delve deeper into the power of offline reinforcement learning.  The general guidelines training will not be outlined here.\n",
    "\n",
    "Let's train `CartPoleSway` again, but this time alter the cost function and create fake transitions to aid the cart to its goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Setting\n",
    "We want the cart to move the position 0 (middle of the screen) from any starting position.  We do not care about the pole.\n",
    "\n",
    "For this, we will generate a cost function that only deals out cost based on position, and create a fake transition set that shows 0 cost at the goal position.\n",
    "\n",
    "*Note the imports inside the functions: this is bad practice but I do it here to show what imports we need.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_episodes(sart_path:str, lookback:int): # ->List[Episode]\n",
    "    \"\"\"Create a fake episode at position 0 for every episode already collected\n",
    "    \n",
    "    Since the cart probably was never at position 0 exactly, we add a set of Episodes with this transition.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    from psipy.rl.io.sart import SARTReader\n",
    "    from psipy.rl.io.batch import Episode\n",
    "    \n",
    "    more_episodes = []\n",
    "\n",
    "    for path in glob.glob(f\"{sart_path}/*.hdf5\"):\n",
    "        with SARTReader(path) as reader:\n",
    "            o, a, t, c = reader.load_full_episode()\n",
    "\n",
    "            # Add episode full of goal states\n",
    "            o = o.copy()\n",
    "            a = a.copy()\n",
    "            o[:, 0] = 0\n",
    "            o[:, 1] = 0\n",
    "            # A swinging pole affects the position of the cart,\n",
    "            # so we say no swing here as well\n",
    "            o[:, 2] = 180\n",
    "            o[:, 3] = 0\n",
    "            a[:] = 0  # The cart should not move once in this position\n",
    "            more_episodes.append(Episode(o, a, t, c, lookback=lookback))\n",
    "            \n",
    "    return more_episodes\n",
    "\n",
    "def costfunc(states:np.ndarray): # -> np.ndarray\n",
    "    \"\"\"Recalculate costs on all states provided\n",
    "    \n",
    "    This calculates costs on multiple states, so it returns an array\n",
    "    \"\"\"\n",
    "    from psipy.rl.control.nfq import tanh2\n",
    "    # Position is already defined against 0 (relative)\n",
    "    position = states[:, 0]\n",
    "    cost = tanh2(position, C=.2, mu=.1)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set everything up until we need to add the fake transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psipy.rl.plant.gym.cartpole_plants import (\n",
    "    CartPoleSwayContAction,\n",
    "    CartPoleSwayContinuousPlant,\n",
    "    CartPoleSwayState,\n",
    ")\n",
    "from psipy.rl.control.nfqca import NFQCA\n",
    "\n",
    "\n",
    "plant = CartPoleSwayContinuousPlant()  # Note that it is instantiated!\n",
    "action = CartPoleSwayContAction\n",
    "state = CartPoleSwayState\n",
    "lookback = 5\n",
    "sart_folder = \"tutorial-advanced-sart\"\n",
    "\n",
    "\n",
    "def make_actor(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_actor\")\n",
    "    net = tfkl.Flatten()(inp)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"tanh\")(net)\n",
    "    return tf.keras.Model(inp, net, name=\"actor\")\n",
    "\n",
    "\n",
    "def make_critic(inputs, lookback):\n",
    "    inp = tfkl.Input((inputs, lookback), name=\"state_critic\")\n",
    "    act = tfkl.Input((1,), name=\"act_in\")\n",
    "    net = tfkl.Concatenate()([tfkl.Flatten()(inp), tfkl.Flatten()(act)])\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(40, activation=\"tanh\")(net)\n",
    "    net = tfkl.Dense(1, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model([inp, act], net, name=\"critic\")\n",
    "\n",
    "actor = make_actor(len(state.channels()), lookback)\n",
    "critic = make_critic(len(state.channels()), lookback)\n",
    "\n",
    "controller = NFQCA(\n",
    "    actor=actor, \n",
    "    critic=critic, \n",
    "    state_channels=state.channels(), \n",
    "    action=CartPoleSwayContAction,\n",
    "    lookback=lookback\n",
    ")\n",
    "\n",
    "loop = Loop(plant, controller, \"CartPolePosition\", sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critic recieves the cost function, and before we start training we want to add our fake goal position transitions.  Therefore, we put `costfunc` in `fit_critic` and append fake episodes before we start the fitting cycles.\n",
    "\n",
    "We will print the size of the batch so it can be seen how the fake episodes increase the batch episode count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 3\n",
    "iterations = 3\n",
    "\n",
    "loop.run(10)\n",
    "batch = Batch.from_hdf5(sart_folder, lookback=lookback, control=controller)\n",
    "print(f\"Current batch size: {batch.num_episodes}\")\n",
    "# We now append the fake created episodes\n",
    "# We could also throw away the created batch and only have the episodes\n",
    "# created in the function by doing:\n",
    "# batch = Batch(create_fake_episodes(sart_folder, lookback))\n",
    "batch = batch.append(create_fake_episodes(sart_folder, lookback))\n",
    "        \n",
    "for cycle in range(num_cycles):\n",
    "    LOG.info(\"Cycle: %d\", cycle + 1)\n",
    "    print(f\"Current batch size: {batch.num_episodes}\")\n",
    "    controller.fit_normalizer(batch.observations, method=\"meanstd\")\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        LOG.info(\"NFQCA Iteration: %d\", iteration + 1)\n",
    "        controller.fit_critic(batch,\n",
    "                         iterations=1,\n",
    "                         # We add the cost function here\n",
    "                         costfunc=costfunc,\n",
    "                         epochs=10,\n",
    "                         minibatch_size=-1,\n",
    "                         gamma=1.0,\n",
    "                         verbose=0)\n",
    "        controller.fit_actor(batch,\n",
    "                        epochs=10,\n",
    "                        minibatch_size=-1,\n",
    "                        verbose=0)\n",
    "\n",
    "    loop = Loop(plant, controller, \"GrowingBatch\", sart_folder)\n",
    "    loop.run(10)\n",
    "    batch.append_from_hdf5(sart_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the controller moves to the goal position.  Oh the tension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Loop(plant, controller, \"GrowingBatchEval\", f\"live-{sart_folder}\", render=True)\n",
    "loop.run(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you've made it through the Advanced Tutorial.  You are now an expert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please delete the SART logs created by this tutorial if you no longer need them.  Or run the cell below to do that automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "dirs = [\"tutorial-advanced-sart\", \n",
    "        \"tutorial-batch-sart\", \n",
    "        \"tutorial-growing-batch\", \n",
    "        \"live-tutorial-growing-sart\", \n",
    "        \"live-tutorial-batch-sart\", \n",
    "        \"live-tutorial-advanced-sart\"]\n",
    "for d in dirs:\n",
    "    try:\n",
    "        shutil.rmtree(d)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
